{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(합성곱 신경망)\n",
    "\n",
    "- 이미지나 비디오 같은 영상 인식에 특화된 설계로, 병렬 처리가 쉬워 대규모 서비스에 적용가능\n",
    "- 최근 이미지뿐 아니라 자연어 처리 추천 시스템에 응용되기도 한다. \n",
    "\n",
    "1) 컴퓨터가 보는 이미지 \n",
    "\n",
    "- 컴퓨터에서 모든 이미지는 픽셀값들을 가로, 세로로 늘어놓은 행렬로 표현할 수 있다. \n",
    "- 일반적인 인공신경망은 다양한 형태의 입력에 대한 확장성이 떨어진다. \n",
    "\n",
    "\n",
    "2) 컨볼루션\n",
    "\n",
    "- 계층적으로 이미지를 인식할 수 있도록 단계마다 이미지의 특징을 추출 하는 것.\n",
    "- 각 단계에서는 이미지에 다양한 필터를 적용하여 윤곽선, 질감, 털 등 각종 특징 추출.\n",
    "- 필터 적용시 이미지 왼쪽 위에서 오른쪽 밑까지 밀어가며 곱하고 더하는데 이 작업을 '컨볼루션'이라고 한다. \n",
    "- 컨볼루션은 모든 종류의 이미지로 확장하기 어렵고, 사람의 실력에 따라 모델 성능이 달라지고, 일이리 작업하기에는 시간과 비용이 크다. \n",
    "- CNN은 이미지를 추출하는 필터를 학습한다. ( 필터 하나가 작은 신경망 )\n",
    "\n",
    "3) CNN모델\n",
    "\n",
    "- 일반적으로 컨볼루션 계층, 풀링 계층, 특징들을 모아 최종 분류하는 일반적인 인공 신경망 계층으로 구성\n",
    "- 컨볼루션 계층은 이미지의 특징을 추출하는 역할, 풀링은 필터를 거친 여러 특징 중 중요한 특징 하나를 골라냄( 나머지는 특징은 버려 차원이 감소)\n",
    "- 풀고자 하는 문제에 따라 계층 구성을 달리 할 수 있으며, 컨볼루션계층만으로 구성된 모델을 만들 수도 있다. \n",
    "- 컨볼루션 연산은 이미지를 겹치는 매우 작은 조각으로 쪼개어 필터 기능을 하는 작은 신경망에 적용 ( 컨볼루션 필터 or 커널 )\n",
    "- 컨볼루션은 오른쪽 아래로 움직이며 이미지를 만든다. 이때 움직임을 조절하는 값을 스트라이드라고 한다. \n",
    "- 컨볼루션을 거쳐 만들어진 새로운 이미지는 특징 맵이라고도 부른다.  이 특징 맵들이 풀링 게층으로 넘어간다. \n",
    "- 특징 맵의 크기가 크면 학습이 어렵고, 과적합의 위험이 증가한다. \n",
    "- CNN은 사물의 치우침에 따라 성능이 변하는 인공신경망의 문제를 해결해주고, 이미지 크기만큼 가중치를 가져야 하는\n",
    "\n",
    "  일반 인공 신경망과는 다르게 필터만을 학습시키면 되어 훨씬 적은 계산량으로 효율적인 학습 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN모델 구현 \n",
    "#컨볼루션 -> 풀링 -> 드롭아웃 -> 풀링 -> 신경망 -> 드롭아웃 -> 신경망\n",
    "#CNN모델의 커널 크기는 5*5 / 컨볼루션 계층은 2개 \n",
    "\n",
    "#라이브러리 로드 \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#쿠다 사용환경 설정\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "#하이퍼파라미터 설정\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "#예제 데이터셋 로드\n",
    "#transforms 이용 전처리는 파이토치 텐서화, 정규화만 적용\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.FashionMNIST('./.data',\n",
    "                                                                train = True,\n",
    "                                                                download = True, \n",
    "                                                                transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                                                               transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                                                                               ]))\n",
    "                                          , batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.FashionMNIST('./.data',\n",
    "                                                                train = False,\n",
    "                                                                download = True, \n",
    "                                                                transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                                                               transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                                                                               ]))\n",
    "                                          , batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Conv2d모듈은 입력 x를 받는 함수를 반환한다 ( 자신을 바로 부를 수 잇지만 함수로 생각해도 무방)\n",
    "#모델의 학습 정의\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #입력채널수 = 1, 출력 채널수 =10 ( 데이터셋이 흑백이미지로 색상 채널이 1개뿐)\n",
    "        #kernel_size로 커널 크기 지정 숫자 하나만 지저앟면 정사각형으로 간주\n",
    "        self.conv1 = nn.Conv2d(1,10, kernel_size = 5)\n",
    "        self.conv2 = nn.Conv2d(10,20, kernel_size = 5)\n",
    "        #컨볼루션 결과로 나온 출력값에 드롭아웃 \n",
    "        self.drop = nn.Dropout2d()\n",
    "        #일반신경망\n",
    "        #위 계층의 출력값인 320을 입력 받고 \n",
    "        #최종 출력을 분류할 클래스 개수인 10개로 설정\n",
    "        self.fc1 = nn.Linear(320,50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        \n",
    "    #출력까지 진행\n",
    "    def forward(self, x):\n",
    "        #두개의 각 컨볼루션 계층을 거친 후, max_pool2d 함수 거치기 / 두번째 입력은 커널 크기\n",
    "        #컨볼루션과 맥스 풀링을 통과한 x는 F.relu함수를 거친다. \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        #2차원의 특징맵을 바로 입력으로 넣을 수 없어 1차원으로 변환(축소)\n",
    "        #view()의 첫 입력 -1은 '남는 모든 차원', 320은 x가 가진 원소갯수\n",
    "        x = x.view(-1, 320)\n",
    "        #앞서 추출한 특징들을 입력으로 받아 분류하는 신경망 계층 구성( 1- ReLu활성화함수 2- 드롭아웃, 3- 0~9레이블)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#`to()` 함수는 모델의 파라미터들을 지정한 곳으로 보내는 역할을 한다. 일반적으로 CPU 1개만 사용할 경우 필요는 없지만, GPU를 사용하고자 하는 경우 `to(\"cuda\")`로 지정하여 GPU로 보내야 한다.\n",
    "# 최적화 알고리즘으로는 토치에 내장되어 있는 `optim.SGD`를 사용(확률적 경사하강법)\n",
    "\n",
    "model     = CNN().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 train모드, F.corss_entropy오차 함수를 이용하여 모델 출력과 정답인 타겟값 사이 오차 계산\n",
    "#역전파 알고리즘을 실행해주는 loss.backward()함수를 이용해 기울기 계산 후, optimizer.step() 최적화 함수로 구한 기울기값으로 학습 파라미터 갱신\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "         #epoch마다 새로운 경사값을 계산하므로 zero_grad()함수를 호출해 경사를 0으로 설정\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output ,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 200 == 0:\n",
    "            print('Train Epoch : {} [{}/{} ({}%)]\\t Loss :{}'.format\n",
    "                 (epoch ,batch_idx*len(data), len(train_loader.dataset), 100.*batch_idx/len(train_loader), loss.item()))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#성능 확인\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    #초기값 설정\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "            \n",
    "            #배치 오차 합산\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "            \n",
    "            #가장 높은 값을 가진 인덱스가 예측값\n",
    "            pred = output.max(1, keepdim = True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100* correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 [0/60000 (0.0%)]\t Loss :4.606046676635742\n",
      "Train Epoch : 1 [12800/60000 (21.321961620469082%)]\t Loss :0.9683188199996948\n",
      "Train Epoch : 1 [25600/60000 (42.643923240938165%)]\t Loss :0.759576678276062\n",
      "Train Epoch : 1 [38400/60000 (63.96588486140725%)]\t Loss :0.7466010451316833\n",
      "Train Epoch : 1 [51200/60000 (85.28784648187633%)]\t Loss :0.9223911166191101\n",
      "[1] Test LOSS : 0.5916794527053832, Accuracy : 77.55\n",
      "Train Epoch : 2 [0/60000 (0.0%)]\t Loss :0.7344424724578857\n",
      "Train Epoch : 2 [12800/60000 (21.321961620469082%)]\t Loss :0.600426435470581\n",
      "Train Epoch : 2 [25600/60000 (42.643923240938165%)]\t Loss :0.7209107875823975\n",
      "Train Epoch : 2 [38400/60000 (63.96588486140725%)]\t Loss :0.5604140758514404\n",
      "Train Epoch : 2 [51200/60000 (85.28784648187633%)]\t Loss :0.5895727872848511\n",
      "[2] Test LOSS : 0.5129018677711487, Accuracy : 81.52\n",
      "Train Epoch : 3 [0/60000 (0.0%)]\t Loss :0.4853051006793976\n",
      "Train Epoch : 3 [12800/60000 (21.321961620469082%)]\t Loss :0.5364071130752563\n",
      "Train Epoch : 3 [25600/60000 (42.643923240938165%)]\t Loss :0.550014078617096\n",
      "Train Epoch : 3 [38400/60000 (63.96588486140725%)]\t Loss :0.4419305920600891\n",
      "Train Epoch : 3 [51200/60000 (85.28784648187633%)]\t Loss :0.6821455955505371\n",
      "[3] Test LOSS : 0.46564400091171265, Accuracy : 82.85\n",
      "Train Epoch : 4 [0/60000 (0.0%)]\t Loss :0.5128501653671265\n",
      "Train Epoch : 4 [12800/60000 (21.321961620469082%)]\t Loss :0.6570776700973511\n",
      "Train Epoch : 4 [25600/60000 (42.643923240938165%)]\t Loss :0.6640521287918091\n",
      "Train Epoch : 4 [38400/60000 (63.96588486140725%)]\t Loss :0.5453586578369141\n",
      "Train Epoch : 4 [51200/60000 (85.28784648187633%)]\t Loss :0.4258442223072052\n",
      "[4] Test LOSS : 0.42421843523979186, Accuracy : 84.46\n",
      "Train Epoch : 5 [0/60000 (0.0%)]\t Loss :0.6347076296806335\n",
      "Train Epoch : 5 [12800/60000 (21.321961620469082%)]\t Loss :0.46370670199394226\n",
      "Train Epoch : 5 [25600/60000 (42.643923240938165%)]\t Loss :0.3132120966911316\n",
      "Train Epoch : 5 [38400/60000 (63.96588486140725%)]\t Loss :0.5180205702781677\n",
      "Train Epoch : 5 [51200/60000 (85.28784648187633%)]\t Loss :0.6208301186561584\n",
      "[5] Test LOSS : 0.4014793193817139, Accuracy : 85.53\n",
      "Train Epoch : 6 [0/60000 (0.0%)]\t Loss :0.6833905577659607\n",
      "Train Epoch : 6 [12800/60000 (21.321961620469082%)]\t Loss :0.39428138732910156\n",
      "Train Epoch : 6 [25600/60000 (42.643923240938165%)]\t Loss :0.4971283972263336\n",
      "Train Epoch : 6 [38400/60000 (63.96588486140725%)]\t Loss :0.5135378837585449\n",
      "Train Epoch : 6 [51200/60000 (85.28784648187633%)]\t Loss :0.5275006890296936\n",
      "[6] Test LOSS : 0.39181911935806274, Accuracy : 86.09\n",
      "Train Epoch : 7 [0/60000 (0.0%)]\t Loss :0.4766131639480591\n",
      "Train Epoch : 7 [12800/60000 (21.321961620469082%)]\t Loss :0.3959067761898041\n",
      "Train Epoch : 7 [25600/60000 (42.643923240938165%)]\t Loss :0.27799856662750244\n",
      "Train Epoch : 7 [38400/60000 (63.96588486140725%)]\t Loss :0.30325478315353394\n",
      "Train Epoch : 7 [51200/60000 (85.28784648187633%)]\t Loss :0.5230923295021057\n",
      "[7] Test LOSS : 0.38866470756530763, Accuracy : 86.18\n",
      "Train Epoch : 8 [0/60000 (0.0%)]\t Loss :0.38876426219940186\n",
      "Train Epoch : 8 [12800/60000 (21.321961620469082%)]\t Loss :0.4360317885875702\n",
      "Train Epoch : 8 [25600/60000 (42.643923240938165%)]\t Loss :0.4265667796134949\n",
      "Train Epoch : 8 [38400/60000 (63.96588486140725%)]\t Loss :0.33444106578826904\n",
      "Train Epoch : 8 [51200/60000 (85.28784648187633%)]\t Loss :0.5553752779960632\n",
      "[8] Test LOSS : 0.37857766790390013, Accuracy : 86.28\n",
      "Train Epoch : 9 [0/60000 (0.0%)]\t Loss :0.41492632031440735\n",
      "Train Epoch : 9 [12800/60000 (21.321961620469082%)]\t Loss :0.45726877450942993\n",
      "Train Epoch : 9 [25600/60000 (42.643923240938165%)]\t Loss :0.41989949345588684\n",
      "Train Epoch : 9 [38400/60000 (63.96588486140725%)]\t Loss :0.5975470542907715\n",
      "Train Epoch : 9 [51200/60000 (85.28784648187633%)]\t Loss :0.5112090706825256\n",
      "[9] Test LOSS : 0.3564462184906006, Accuracy : 87.09\n",
      "Train Epoch : 10 [0/60000 (0.0%)]\t Loss :0.5514660477638245\n",
      "Train Epoch : 10 [12800/60000 (21.321961620469082%)]\t Loss :0.43339771032333374\n",
      "Train Epoch : 10 [25600/60000 (42.643923240938165%)]\t Loss :0.6663314700126648\n",
      "Train Epoch : 10 [38400/60000 (63.96588486140725%)]\t Loss :0.40307530760765076\n",
      "Train Epoch : 10 [51200/60000 (85.28784648187633%)]\t Loss :0.26426026225090027\n",
      "[10] Test LOSS : 0.35043772473335266, Accuracy : 87.36\n",
      "Train Epoch : 11 [0/60000 (0.0%)]\t Loss :0.34527021646499634\n",
      "Train Epoch : 11 [12800/60000 (21.321961620469082%)]\t Loss :0.3222880959510803\n",
      "Train Epoch : 11 [25600/60000 (42.643923240938165%)]\t Loss :0.19089782238006592\n",
      "Train Epoch : 11 [38400/60000 (63.96588486140725%)]\t Loss :0.4088405966758728\n",
      "Train Epoch : 11 [51200/60000 (85.28784648187633%)]\t Loss :0.4386676251888275\n",
      "[11] Test LOSS : 0.35309449162483214, Accuracy : 87.45\n",
      "Train Epoch : 12 [0/60000 (0.0%)]\t Loss :0.2983352541923523\n",
      "Train Epoch : 12 [12800/60000 (21.321961620469082%)]\t Loss :0.43897977471351624\n",
      "Train Epoch : 12 [25600/60000 (42.643923240938165%)]\t Loss :0.6505496501922607\n",
      "Train Epoch : 12 [38400/60000 (63.96588486140725%)]\t Loss :0.4049511253833771\n",
      "Train Epoch : 12 [51200/60000 (85.28784648187633%)]\t Loss :0.303887277841568\n",
      "[12] Test LOSS : 0.3447503613233566, Accuracy : 87.6\n",
      "Train Epoch : 13 [0/60000 (0.0%)]\t Loss :0.6499768495559692\n",
      "Train Epoch : 13 [12800/60000 (21.321961620469082%)]\t Loss :0.40247219800949097\n",
      "Train Epoch : 13 [25600/60000 (42.643923240938165%)]\t Loss :0.6645681858062744\n",
      "Train Epoch : 13 [38400/60000 (63.96588486140725%)]\t Loss :0.4679454565048218\n",
      "Train Epoch : 13 [51200/60000 (85.28784648187633%)]\t Loss :0.30758124589920044\n",
      "[13] Test LOSS : 0.3368573941707611, Accuracy : 88.01\n",
      "Train Epoch : 14 [0/60000 (0.0%)]\t Loss :0.4724865257740021\n",
      "Train Epoch : 14 [12800/60000 (21.321961620469082%)]\t Loss :0.31762418150901794\n",
      "Train Epoch : 14 [25600/60000 (42.643923240938165%)]\t Loss :0.33988460898399353\n",
      "Train Epoch : 14 [38400/60000 (63.96588486140725%)]\t Loss :0.39324504137039185\n",
      "Train Epoch : 14 [51200/60000 (85.28784648187633%)]\t Loss :0.44171857833862305\n",
      "[14] Test LOSS : 0.33636144423484804, Accuracy : 87.47\n",
      "Train Epoch : 15 [0/60000 (0.0%)]\t Loss :0.5483278632164001\n",
      "Train Epoch : 15 [12800/60000 (21.321961620469082%)]\t Loss :0.4147915840148926\n",
      "Train Epoch : 15 [25600/60000 (42.643923240938165%)]\t Loss :0.29900166392326355\n",
      "Train Epoch : 15 [38400/60000 (63.96588486140725%)]\t Loss :0.18773899972438812\n",
      "Train Epoch : 15 [51200/60000 (85.28784648187633%)]\t Loss :0.37451913952827454\n",
      "[15] Test LOSS : 0.3248007229804993, Accuracy : 88.4\n",
      "Train Epoch : 16 [0/60000 (0.0%)]\t Loss :0.4315788149833679\n",
      "Train Epoch : 16 [12800/60000 (21.321961620469082%)]\t Loss :0.6399356126785278\n",
      "Train Epoch : 16 [25600/60000 (42.643923240938165%)]\t Loss :0.5672917366027832\n",
      "Train Epoch : 16 [38400/60000 (63.96588486140725%)]\t Loss :0.34866443276405334\n",
      "Train Epoch : 16 [51200/60000 (85.28784648187633%)]\t Loss :0.41003039479255676\n",
      "[16] Test LOSS : 0.3199843770980835, Accuracy : 88.16\n",
      "Train Epoch : 17 [0/60000 (0.0%)]\t Loss :0.5393654704093933\n",
      "Train Epoch : 17 [12800/60000 (21.321961620469082%)]\t Loss :0.39986830949783325\n",
      "Train Epoch : 17 [25600/60000 (42.643923240938165%)]\t Loss :0.25376468896865845\n",
      "Train Epoch : 17 [38400/60000 (63.96588486140725%)]\t Loss :0.2474282830953598\n",
      "Train Epoch : 17 [51200/60000 (85.28784648187633%)]\t Loss :0.21681132912635803\n",
      "[17] Test LOSS : 0.31885316171646116, Accuracy : 88.36\n",
      "Train Epoch : 18 [0/60000 (0.0%)]\t Loss :0.20010130107402802\n",
      "Train Epoch : 18 [12800/60000 (21.321961620469082%)]\t Loss :0.3632267713546753\n",
      "Train Epoch : 18 [25600/60000 (42.643923240938165%)]\t Loss :0.35449180006980896\n",
      "Train Epoch : 18 [38400/60000 (63.96588486140725%)]\t Loss :0.25427982211112976\n",
      "Train Epoch : 18 [51200/60000 (85.28784648187633%)]\t Loss :0.2538183629512787\n",
      "[18] Test LOSS : 0.3190385572195053, Accuracy : 88.48\n",
      "Train Epoch : 19 [0/60000 (0.0%)]\t Loss :0.5019006133079529\n",
      "Train Epoch : 19 [12800/60000 (21.321961620469082%)]\t Loss :0.39903777837753296\n",
      "Train Epoch : 19 [25600/60000 (42.643923240938165%)]\t Loss :0.45901593565940857\n",
      "Train Epoch : 19 [38400/60000 (63.96588486140725%)]\t Loss :0.23933899402618408\n",
      "Train Epoch : 19 [51200/60000 (85.28784648187633%)]\t Loss :0.34008023142814636\n",
      "[19] Test LOSS : 0.3270583952903748, Accuracy : 88.27\n",
      "Train Epoch : 20 [0/60000 (0.0%)]\t Loss :0.2309695929288864\n",
      "Train Epoch : 20 [12800/60000 (21.321961620469082%)]\t Loss :0.3746333122253418\n",
      "Train Epoch : 20 [25600/60000 (42.643923240938165%)]\t Loss :0.3126312792301178\n",
      "Train Epoch : 20 [38400/60000 (63.96588486140725%)]\t Loss :0.35701870918273926\n",
      "Train Epoch : 20 [51200/60000 (85.28784648187633%)]\t Loss :0.4005564749240875\n",
      "[20] Test LOSS : 0.31032305245995523, Accuracy : 88.62\n",
      "Train Epoch : 21 [0/60000 (0.0%)]\t Loss :0.3411749303340912\n",
      "Train Epoch : 21 [12800/60000 (21.321961620469082%)]\t Loss :0.2671954333782196\n",
      "Train Epoch : 21 [25600/60000 (42.643923240938165%)]\t Loss :0.3378481864929199\n",
      "Train Epoch : 21 [38400/60000 (63.96588486140725%)]\t Loss :0.6160414218902588\n",
      "Train Epoch : 21 [51200/60000 (85.28784648187633%)]\t Loss :0.16964514553546906\n",
      "[21] Test LOSS : 0.31203612394332886, Accuracy : 88.74\n",
      "Train Epoch : 22 [0/60000 (0.0%)]\t Loss :0.26978573203086853\n",
      "Train Epoch : 22 [12800/60000 (21.321961620469082%)]\t Loss :0.5549207925796509\n",
      "Train Epoch : 22 [25600/60000 (42.643923240938165%)]\t Loss :0.214967280626297\n",
      "Train Epoch : 22 [38400/60000 (63.96588486140725%)]\t Loss :0.2305537313222885\n",
      "Train Epoch : 22 [51200/60000 (85.28784648187633%)]\t Loss :0.4350774884223938\n",
      "[22] Test LOSS : 0.3095547572731972, Accuracy : 88.86\n",
      "Train Epoch : 23 [0/60000 (0.0%)]\t Loss :0.28116172552108765\n",
      "Train Epoch : 23 [12800/60000 (21.321961620469082%)]\t Loss :0.3259187936782837\n",
      "Train Epoch : 23 [25600/60000 (42.643923240938165%)]\t Loss :0.13529102504253387\n",
      "Train Epoch : 23 [38400/60000 (63.96588486140725%)]\t Loss :0.3045404553413391\n",
      "Train Epoch : 23 [51200/60000 (85.28784648187633%)]\t Loss :0.36600103974342346\n",
      "[23] Test LOSS : 0.30648912358284, Accuracy : 88.86\n",
      "Train Epoch : 24 [0/60000 (0.0%)]\t Loss :0.3053089678287506\n",
      "Train Epoch : 24 [12800/60000 (21.321961620469082%)]\t Loss :0.2964053153991699\n",
      "Train Epoch : 24 [25600/60000 (42.643923240938165%)]\t Loss :0.26000678539276123\n",
      "Train Epoch : 24 [38400/60000 (63.96588486140725%)]\t Loss :0.42684996128082275\n",
      "Train Epoch : 24 [51200/60000 (85.28784648187633%)]\t Loss :0.2923881411552429\n",
      "[24] Test LOSS : 0.29742770701646803, Accuracy : 89.08\n",
      "Train Epoch : 25 [0/60000 (0.0%)]\t Loss :0.24884262681007385\n",
      "Train Epoch : 25 [12800/60000 (21.321961620469082%)]\t Loss :0.3144056797027588\n",
      "Train Epoch : 25 [25600/60000 (42.643923240938165%)]\t Loss :0.18896053731441498\n",
      "Train Epoch : 25 [38400/60000 (63.96588486140725%)]\t Loss :0.3936817944049835\n",
      "Train Epoch : 25 [51200/60000 (85.28784648187633%)]\t Loss :0.26582008600234985\n",
      "[25] Test LOSS : 0.303101858663559, Accuracy : 89.14\n",
      "Train Epoch : 26 [0/60000 (0.0%)]\t Loss :0.44674503803253174\n",
      "Train Epoch : 26 [12800/60000 (21.321961620469082%)]\t Loss :0.2446005940437317\n",
      "Train Epoch : 26 [25600/60000 (42.643923240938165%)]\t Loss :0.23298300802707672\n",
      "Train Epoch : 26 [38400/60000 (63.96588486140725%)]\t Loss :0.37732425332069397\n",
      "Train Epoch : 26 [51200/60000 (85.28784648187633%)]\t Loss :0.2490844577550888\n",
      "[26] Test LOSS : 0.29703192925453187, Accuracy : 89.13\n",
      "Train Epoch : 27 [0/60000 (0.0%)]\t Loss :0.2845395505428314\n",
      "Train Epoch : 27 [12800/60000 (21.321961620469082%)]\t Loss :0.2515188455581665\n",
      "Train Epoch : 27 [25600/60000 (42.643923240938165%)]\t Loss :0.3430306613445282\n",
      "Train Epoch : 27 [38400/60000 (63.96588486140725%)]\t Loss :0.471625417470932\n",
      "Train Epoch : 27 [51200/60000 (85.28784648187633%)]\t Loss :0.2236994206905365\n",
      "[27] Test LOSS : 0.30126526012420657, Accuracy : 89.0\n",
      "Train Epoch : 28 [0/60000 (0.0%)]\t Loss :0.3824462294578552\n",
      "Train Epoch : 28 [12800/60000 (21.321961620469082%)]\t Loss :0.3291831612586975\n",
      "Train Epoch : 28 [25600/60000 (42.643923240938165%)]\t Loss :0.3913780748844147\n",
      "Train Epoch : 28 [38400/60000 (63.96588486140725%)]\t Loss :0.329917311668396\n",
      "Train Epoch : 28 [51200/60000 (85.28784648187633%)]\t Loss :0.3508826196193695\n",
      "[28] Test LOSS : 0.29980263872146606, Accuracy : 89.08\n",
      "Train Epoch : 29 [0/60000 (0.0%)]\t Loss :0.23388326168060303\n",
      "Train Epoch : 29 [12800/60000 (21.321961620469082%)]\t Loss :0.37205979228019714\n",
      "Train Epoch : 29 [25600/60000 (42.643923240938165%)]\t Loss :0.23909282684326172\n",
      "Train Epoch : 29 [38400/60000 (63.96588486140725%)]\t Loss :0.3153076767921448\n",
      "Train Epoch : 29 [51200/60000 (85.28784648187633%)]\t Loss :0.38135817646980286\n",
      "[29] Test LOSS : 0.298591131067276, Accuracy : 89.29\n",
      "Train Epoch : 30 [0/60000 (0.0%)]\t Loss :0.12340888381004333\n",
      "Train Epoch : 30 [12800/60000 (21.321961620469082%)]\t Loss :0.27292484045028687\n",
      "Train Epoch : 30 [25600/60000 (42.643923240938165%)]\t Loss :0.2906394302845001\n",
      "Train Epoch : 30 [38400/60000 (63.96588486140725%)]\t Loss :0.35277169942855835\n",
      "Train Epoch : 30 [51200/60000 (85.28784648187633%)]\t Loss :0.1944596916437149\n",
      "[30] Test LOSS : 0.293354749250412, Accuracy : 89.42\n",
      "Train Epoch : 31 [0/60000 (0.0%)]\t Loss :0.12186667323112488\n",
      "Train Epoch : 31 [12800/60000 (21.321961620469082%)]\t Loss :0.26734909415245056\n",
      "Train Epoch : 31 [25600/60000 (42.643923240938165%)]\t Loss :0.5106984376907349\n",
      "Train Epoch : 31 [38400/60000 (63.96588486140725%)]\t Loss :0.32192444801330566\n",
      "Train Epoch : 31 [51200/60000 (85.28784648187633%)]\t Loss :0.49092814326286316\n",
      "[31] Test LOSS : 0.304116719353199, Accuracy : 89.37\n",
      "Train Epoch : 32 [0/60000 (0.0%)]\t Loss :0.3296079635620117\n",
      "Train Epoch : 32 [12800/60000 (21.321961620469082%)]\t Loss :0.3786540627479553\n",
      "Train Epoch : 32 [25600/60000 (42.643923240938165%)]\t Loss :0.35139229893684387\n",
      "Train Epoch : 32 [38400/60000 (63.96588486140725%)]\t Loss :0.21248497068881989\n",
      "Train Epoch : 32 [51200/60000 (85.28784648187633%)]\t Loss :0.2759711742401123\n",
      "[32] Test LOSS : 0.2930365395784378, Accuracy : 89.4\n",
      "Train Epoch : 33 [0/60000 (0.0%)]\t Loss :0.3529321253299713\n",
      "Train Epoch : 33 [12800/60000 (21.321961620469082%)]\t Loss :0.20155847072601318\n",
      "Train Epoch : 33 [25600/60000 (42.643923240938165%)]\t Loss :0.1365121454000473\n",
      "Train Epoch : 33 [38400/60000 (63.96588486140725%)]\t Loss :0.27280309796333313\n",
      "Train Epoch : 33 [51200/60000 (85.28784648187633%)]\t Loss :0.2365802675485611\n",
      "[33] Test LOSS : 0.2983212586164474, Accuracy : 89.12\n",
      "Train Epoch : 34 [0/60000 (0.0%)]\t Loss :0.24056130647659302\n",
      "Train Epoch : 34 [12800/60000 (21.321961620469082%)]\t Loss :0.3072271943092346\n",
      "Train Epoch : 34 [25600/60000 (42.643923240938165%)]\t Loss :0.19912190735340118\n",
      "Train Epoch : 34 [38400/60000 (63.96588486140725%)]\t Loss :0.23673059046268463\n",
      "Train Epoch : 34 [51200/60000 (85.28784648187633%)]\t Loss :0.3935358226299286\n",
      "[34] Test LOSS : 0.2933594763278961, Accuracy : 89.71\n",
      "Train Epoch : 35 [0/60000 (0.0%)]\t Loss :0.33684244751930237\n",
      "Train Epoch : 35 [12800/60000 (21.321961620469082%)]\t Loss :0.19441576302051544\n",
      "Train Epoch : 35 [25600/60000 (42.643923240938165%)]\t Loss :0.2970338761806488\n",
      "Train Epoch : 35 [38400/60000 (63.96588486140725%)]\t Loss :0.3310915529727936\n",
      "Train Epoch : 35 [51200/60000 (85.28784648187633%)]\t Loss :0.30948275327682495\n",
      "[35] Test LOSS : 0.2884393530607223, Accuracy : 89.67\n",
      "Train Epoch : 36 [0/60000 (0.0%)]\t Loss :0.3046397268772125\n",
      "Train Epoch : 36 [12800/60000 (21.321961620469082%)]\t Loss :0.36388686299324036\n",
      "Train Epoch : 36 [25600/60000 (42.643923240938165%)]\t Loss :0.4937434494495392\n",
      "Train Epoch : 36 [38400/60000 (63.96588486140725%)]\t Loss :0.2823422849178314\n",
      "Train Epoch : 36 [51200/60000 (85.28784648187633%)]\t Loss :0.23920084536075592\n",
      "[36] Test LOSS : 0.3048511961221695, Accuracy : 89.0\n",
      "Train Epoch : 37 [0/60000 (0.0%)]\t Loss :0.3370726406574249\n",
      "Train Epoch : 37 [12800/60000 (21.321961620469082%)]\t Loss :0.1782752424478531\n",
      "Train Epoch : 37 [25600/60000 (42.643923240938165%)]\t Loss :0.2665432393550873\n",
      "Train Epoch : 37 [38400/60000 (63.96588486140725%)]\t Loss :0.21438255906105042\n",
      "Train Epoch : 37 [51200/60000 (85.28784648187633%)]\t Loss :0.2622632384300232\n",
      "[37] Test LOSS : 0.31302597594261167, Accuracy : 88.74\n",
      "Train Epoch : 38 [0/60000 (0.0%)]\t Loss :0.3523372709751129\n",
      "Train Epoch : 38 [12800/60000 (21.321961620469082%)]\t Loss :0.31131574511528015\n",
      "Train Epoch : 38 [25600/60000 (42.643923240938165%)]\t Loss :0.17664599418640137\n",
      "Train Epoch : 38 [38400/60000 (63.96588486140725%)]\t Loss :0.3604702353477478\n",
      "Train Epoch : 38 [51200/60000 (85.28784648187633%)]\t Loss :0.24920794367790222\n",
      "[38] Test LOSS : 0.29420767192840575, Accuracy : 89.19\n",
      "Train Epoch : 39 [0/60000 (0.0%)]\t Loss :0.42987188696861267\n",
      "Train Epoch : 39 [12800/60000 (21.321961620469082%)]\t Loss :0.2684212625026703\n",
      "Train Epoch : 39 [25600/60000 (42.643923240938165%)]\t Loss :0.32675448060035706\n",
      "Train Epoch : 39 [38400/60000 (63.96588486140725%)]\t Loss :0.40425416827201843\n",
      "Train Epoch : 39 [51200/60000 (85.28784648187633%)]\t Loss :0.21630360186100006\n",
      "[39] Test LOSS : 0.28934834690093997, Accuracy : 89.76\n",
      "Train Epoch : 40 [0/60000 (0.0%)]\t Loss :0.49405375123023987\n",
      "Train Epoch : 40 [12800/60000 (21.321961620469082%)]\t Loss :0.2534908056259155\n",
      "Train Epoch : 40 [25600/60000 (42.643923240938165%)]\t Loss :0.2730010151863098\n",
      "Train Epoch : 40 [38400/60000 (63.96588486140725%)]\t Loss :0.2416168600320816\n",
      "Train Epoch : 40 [51200/60000 (85.28784648187633%)]\t Loss :0.3135702908039093\n",
      "[40] Test LOSS : 0.2946149095535278, Accuracy : 89.81\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "for epoch in range(1, EPOCHS +1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test LOSS : {}, Accuracy : {}'.format(epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인공 신경망과 드롭아웃 조합보다 약 1%이상이 개선되었다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
