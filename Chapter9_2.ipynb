{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cGAN으로 생성 제어하기 \n",
    "\n",
    "- GAN이 더욱 쓸모 있으려면 사용자가 원하는 이미지를 생성하는 기능 제공해야 한다. \n",
    "- 생성과정에서 생성하고자 하는 레이블 정보를 추가로 넣어 원하는 이미지가 나오게끔 모델 수정\n",
    "- 앞의 생성 이미지는 어러 종류의 패션 아이템을 무작위 벡터를 입력받아 출력한 것이다. \n",
    "- 조건부 GAN (cGAN)의 생성자는 학습 과정에서 생성하고픈 아이템의 종류를 입력받아야 한다. \n",
    "  - 이를 구현하는 방법은 생성자와 판별자의 입력에 레이블 정보를 이어 붙이는 것이다. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 장치 이용 : cpu\n"
     ]
    }
   ],
   "source": [
    "#라이브러리 임포트\n",
    "import os \n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#하이퍼 파라미터 설정\n",
    "\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 100\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "print('다음 장치 이용 :', DEVICE)\n",
    "\n",
    "#데이터셋 로드 \n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    './.data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#생성자 \n",
    "#이번 예제는 무작위 텐서(z)의 크기를 100개로 지정\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #연속적인 값이 학습에 유용하여 배치 x1 크기의 레이블 텐서를 받아 배치 x10의 연속적인 텐서로 전환 \n",
    "        self.embed = nn.Embedding(10,10)\n",
    "        \n",
    "        #생성자의 첫 입력이 110개인 이유는 텐서크기100, 레이블값10이 더해진 값\n",
    "        self.model = nn.Sequential(nn.Linear(110,256),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True), #inplace는 입력을 복사하지 않고 바로 조작설정 변수\n",
    "                                  nn.Linear(256, 512),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Linear(512, 1024),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Linear(1024, 784),\n",
    "                                  nn.Tanh())\n",
    "        \n",
    "    def forward(self, z, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([z, c], 1) #두 벡터를 이어 붙이는 연산, 무작위 벡터와 클래스 레이블을 이어붙이고 생성자에 입력 \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#판별자\n",
    "#판별자 역시 레이블 정보를 받는다. \n",
    "#생성자에서 이미지를 만들때 쓴 레이블 정보를 입력받아 '레이블이 주어진 경우의 가짜인 확률과 진짜인 확률을 추정한다'라고 생각하면된다. \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed = nn.Embedding(10,10)\n",
    "        \n",
    "        #판별자에도 생성자의 출력값(이미지크기)에 10을 더해준다\n",
    "        #1024노드 출력계층과, 성능을 위해 각 계층 사이의 드롭아웃 계층을 추가 \n",
    "        #마지막은 Sigmoid함수를 거쳐 참, 거짓을 뜻하는 0~1사이 값 반환 \n",
    "        self.model = nn.Sequential(nn.Linear(794, 1024),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(1024, 512),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(512, 256),\n",
    "                                  nn.LeakyReLU(0.2, inplace = True),\n",
    "                                  nn.Dropout(0.3),\n",
    "                                  nn.Linear(256,1),\n",
    "                                  nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        c = self.embed(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델의 인스턴스를 만들고, 모델의 가중치를 지정 장치로 보낸다. \n",
    "D = Discriminator().to(DEVICE)\n",
    "G = Generator().to(DEVICE)\n",
    "\n",
    "#이진교차 엔트로피 오차함수, 생성자 판별자를 최적화할 Adam모듈 설정 \n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr = 0.0002)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 0/50  //  d_loss  :  1.389394998550415  // g_loss :  0.39439141750335693  // D(x) : 0.4751477837562561  // D(G(z)) :  0.4751477837562561\n",
      "EPOCH : 1/50  //  d_loss  :  1.388519525527954  // g_loss :  0.4014612138271332  // D(x) : 0.47970935702323914  // D(G(z)) :  0.47970935702323914\n",
      "EPOCH : 2/50  //  d_loss  :  1.3892841339111328  // g_loss :  0.3967306911945343  // D(x) : 0.4762822687625885  // D(G(z)) :  0.4762822687625885\n",
      "EPOCH : 3/50  //  d_loss  :  1.3892929553985596  // g_loss :  0.3967667818069458  // D(x) : 0.4758261442184448  // D(G(z)) :  0.4758261442184448\n",
      "EPOCH : 4/50  //  d_loss  :  1.3893404006958008  // g_loss :  0.3965621888637543  // D(x) : 0.4770349860191345  // D(G(z)) :  0.4770349860191345\n",
      "EPOCH : 5/50  //  d_loss  :  1.389049768447876  // g_loss :  0.3941905200481415  // D(x) : 0.47767341136932373  // D(G(z)) :  0.47767341136932373\n",
      "EPOCH : 6/50  //  d_loss  :  1.3887007236480713  // g_loss :  0.3961203396320343  // D(x) : 0.47898852825164795  // D(G(z)) :  0.47898852825164795\n",
      "EPOCH : 7/50  //  d_loss  :  1.388649582862854  // g_loss :  0.3957282602787018  // D(x) : 0.47956475615501404  // D(G(z)) :  0.47956475615501404\n",
      "EPOCH : 8/50  //  d_loss  :  1.389060139656067  // g_loss :  0.3942272663116455  // D(x) : 0.4770318269729614  // D(G(z)) :  0.4770318269729614\n",
      "EPOCH : 9/50  //  d_loss  :  1.3888334035873413  // g_loss :  0.3907873034477234  // D(x) : 0.47835853695869446  // D(G(z)) :  0.47835853695869446\n",
      "EPOCH : 10/50  //  d_loss  :  1.3891688585281372  // g_loss :  0.39948588609695435  // D(x) : 0.4776029884815216  // D(G(z)) :  0.4776029884815216\n",
      "EPOCH : 11/50  //  d_loss  :  1.3888640403747559  // g_loss :  0.3974783420562744  // D(x) : 0.478352427482605  // D(G(z)) :  0.478352427482605\n",
      "EPOCH : 12/50  //  d_loss  :  1.389177918434143  // g_loss :  0.3996131420135498  // D(x) : 0.4760926067829132  // D(G(z)) :  0.4760926067829132\n",
      "EPOCH : 13/50  //  d_loss  :  1.3888585567474365  // g_loss :  0.4018738567829132  // D(x) : 0.47844070196151733  // D(G(z)) :  0.47844070196151733\n",
      "EPOCH : 14/50  //  d_loss  :  1.3888044357299805  // g_loss :  0.3957441747188568  // D(x) : 0.47782137989997864  // D(G(z)) :  0.47782137989997864\n",
      "EPOCH : 15/50  //  d_loss  :  1.3886151313781738  // g_loss :  0.39772164821624756  // D(x) : 0.47931644320487976  // D(G(z)) :  0.47931644320487976\n",
      "EPOCH : 16/50  //  d_loss  :  1.3897780179977417  // g_loss :  0.40397265553474426  // D(x) : 0.4741264581680298  // D(G(z)) :  0.4741264581680298\n",
      "EPOCH : 17/50  //  d_loss  :  1.3891217708587646  // g_loss :  0.40011951327323914  // D(x) : 0.4767337143421173  // D(G(z)) :  0.4767337143421173\n",
      "EPOCH : 18/50  //  d_loss  :  1.389366626739502  // g_loss :  0.401543527841568  // D(x) : 0.47588786482810974  // D(G(z)) :  0.47588786482810974\n",
      "EPOCH : 19/50  //  d_loss  :  1.3891726732254028  // g_loss :  0.39731407165527344  // D(x) : 0.4769876003265381  // D(G(z)) :  0.4769876003265381\n",
      "EPOCH : 20/50  //  d_loss  :  1.389164924621582  // g_loss :  0.39913269877433777  // D(x) : 0.47764256596565247  // D(G(z)) :  0.47764256596565247\n",
      "EPOCH : 21/50  //  d_loss  :  1.389007806777954  // g_loss :  0.3986022472381592  // D(x) : 0.47785618901252747  // D(G(z)) :  0.47785618901252747\n",
      "EPOCH : 22/50  //  d_loss  :  1.3892359733581543  // g_loss :  0.3965494930744171  // D(x) : 0.4757705330848694  // D(G(z)) :  0.4757705330848694\n",
      "EPOCH : 23/50  //  d_loss  :  1.3894851207733154  // g_loss :  0.3882206678390503  // D(x) : 0.47470545768737793  // D(G(z)) :  0.47470545768737793\n",
      "EPOCH : 24/50  //  d_loss  :  1.3892691135406494  // g_loss :  0.3952680230140686  // D(x) : 0.4760521650314331  // D(G(z)) :  0.4760521650314331\n",
      "EPOCH : 25/50  //  d_loss  :  1.3892544507980347  // g_loss :  0.3966571092605591  // D(x) : 0.4756198525428772  // D(G(z)) :  0.4756198525428772\n",
      "EPOCH : 26/50  //  d_loss  :  1.3886117935180664  // g_loss :  0.3969522714614868  // D(x) : 0.47883498668670654  // D(G(z)) :  0.47883498668670654\n",
      "EPOCH : 27/50  //  d_loss  :  1.3888254165649414  // g_loss :  0.3982248306274414  // D(x) : 0.47824108600616455  // D(G(z)) :  0.47824108600616455\n",
      "EPOCH : 28/50  //  d_loss  :  1.3890516757965088  // g_loss :  0.3919936716556549  // D(x) : 0.477479487657547  // D(G(z)) :  0.477479487657547\n",
      "EPOCH : 29/50  //  d_loss  :  1.3894128799438477  // g_loss :  0.3989148437976837  // D(x) : 0.47559380531311035  // D(G(z)) :  0.47559380531311035\n",
      "EPOCH : 30/50  //  d_loss  :  1.3892343044281006  // g_loss :  0.39770886301994324  // D(x) : 0.4761011600494385  // D(G(z)) :  0.4761011600494385\n",
      "EPOCH : 31/50  //  d_loss  :  1.3887081146240234  // g_loss :  0.39413490891456604  // D(x) : 0.4783647060394287  // D(G(z)) :  0.4783647060394287\n",
      "EPOCH : 32/50  //  d_loss  :  1.388366460800171  // g_loss :  0.3969489634037018  // D(x) : 0.4809389114379883  // D(G(z)) :  0.4809389114379883\n",
      "EPOCH : 33/50  //  d_loss  :  1.3892951011657715  // g_loss :  0.3930218517780304  // D(x) : 0.4751286208629608  // D(G(z)) :  0.4751286208629608\n",
      "EPOCH : 34/50  //  d_loss  :  1.3890528678894043  // g_loss :  0.3991120457649231  // D(x) : 0.4767652451992035  // D(G(z)) :  0.4767652451992035\n",
      "EPOCH : 35/50  //  d_loss  :  1.3889946937561035  // g_loss :  0.38919663429260254  // D(x) : 0.477618932723999  // D(G(z)) :  0.477618932723999\n",
      "EPOCH : 36/50  //  d_loss  :  1.388767957687378  // g_loss :  0.40005630254745483  // D(x) : 0.47836223244667053  // D(G(z)) :  0.47836223244667053\n",
      "EPOCH : 37/50  //  d_loss  :  1.3890012502670288  // g_loss :  0.40276050567626953  // D(x) : 0.47794806957244873  // D(G(z)) :  0.47794806957244873\n",
      "EPOCH : 38/50  //  d_loss  :  1.3887814283370972  // g_loss :  0.3934207856655121  // D(x) : 0.4790459871292114  // D(G(z)) :  0.4790459871292114\n",
      "EPOCH : 39/50  //  d_loss  :  1.389067530632019  // g_loss :  0.3962816298007965  // D(x) : 0.4772878885269165  // D(G(z)) :  0.4772878885269165\n",
      "EPOCH : 40/50  //  d_loss  :  1.3892138004302979  // g_loss :  0.3968156576156616  // D(x) : 0.47725215554237366  // D(G(z)) :  0.47725215554237366\n",
      "EPOCH : 41/50  //  d_loss  :  1.3894352912902832  // g_loss :  0.3880612254142761  // D(x) : 0.47474440932273865  // D(G(z)) :  0.47474440932273865\n",
      "EPOCH : 42/50  //  d_loss  :  1.3891522884368896  // g_loss :  0.401704877614975  // D(x) : 0.4772442877292633  // D(G(z)) :  0.4772442877292633\n",
      "EPOCH : 43/50  //  d_loss  :  1.38922119140625  // g_loss :  0.39487943053245544  // D(x) : 0.47613513469696045  // D(G(z)) :  0.47613513469696045\n",
      "EPOCH : 44/50  //  d_loss  :  1.389237880706787  // g_loss :  0.3995243310928345  // D(x) : 0.4757304787635803  // D(G(z)) :  0.4757304787635803\n",
      "EPOCH : 45/50  //  d_loss  :  1.388612985610962  // g_loss :  0.3989291489124298  // D(x) : 0.47943034768104553  // D(G(z)) :  0.47943034768104553\n",
      "EPOCH : 46/50  //  d_loss  :  1.3890652656555176  // g_loss :  0.39041057229042053  // D(x) : 0.47793692350387573  // D(G(z)) :  0.47793692350387573\n",
      "EPOCH : 47/50  //  d_loss  :  1.3889729976654053  // g_loss :  0.39547663927078247  // D(x) : 0.4774228036403656  // D(G(z)) :  0.4774228036403656\n",
      "EPOCH : 48/50  //  d_loss  :  1.388796091079712  // g_loss :  0.3944492042064667  // D(x) : 0.47851672768592834  // D(G(z)) :  0.47851672768592834\n",
      "EPOCH : 49/50  //  d_loss  :  1.3892617225646973  // g_loss :  0.3912135064601898  // D(x) : 0.4760957956314087  // D(G(z)) :  0.4760957956314087\n"
     ]
    }
   ],
   "source": [
    "#데이터 로더(trian_loader)의 두 번째 반환값도 사용할 것이므로 레이블 표기\n",
    "#일반 GAN 예제와 같이 진짜와 가짜 레이블 만든다. \n",
    "\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE)\n",
    "        \n",
    "        #진짜, 가짜 레이블 생성\n",
    "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE)\n",
    "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE)\n",
    "        \n",
    "        #판별자가 진짜 이미지를 인식하는 오차를 계산(데이터셋의 레이블을 입력해 판별자가 이미지와 레이블의 관계를 학습하게 한다. )\n",
    "        labels = labels.to(DEVICE)\n",
    "        outputs = D(images, labels)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs \n",
    "        \n",
    "        #무작위 텐서 생성 - 0~10사이의 값을 가친 배치x1 크기의 텐서를 만들고 생성자에 입력해 관계성 학습\n",
    "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE)\n",
    "        g_label = torch.randint(0,10, (BATCH_SIZE,)).to(DEVICE)\n",
    "        fake_images=G(z, g_label)\n",
    "        \n",
    "        #가짜 이미지를 판별자에게 입력하고, 생성자가 이용한 레이블과 결과물 이미지를 보고 가짜라고 인식하는 오차 계산\n",
    "        ouputs = D(fake_images, g_label)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        #진짜, 가짜, 각 레이블을 보고 계산한 판별자의 총오차 계산하고 역전파 알고리즘으로 판별자의 학습 진행\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "        d_optimizer.zero_grad()#기울기 초기화\n",
    "        g_optimizer.zero_grad()\n",
    "        d_loss.backward()#역전파 \n",
    "        d_optimizer.step\n",
    "        \n",
    "        #생성자도 z와 g_label로 이미지를 생성하고 판별자를 속이는지에 대한 오차 계산\n",
    "        fake_images = G(z, g_label)\n",
    "        outputs = D(fake_images, g_label)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        #역전파 알고리즘으로 생성자 모델의 학습진행\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "    #학습진행\n",
    "    #딥러닝 환경이 원활하지 않아 epoch를 50회만 진행하여 성능이 떨어짐 \n",
    "    #판별자의 오차 = d_loss // 생성자의 오차 = g_loss // 판별자가 진짜를 진짜로 인식 정확도 = D(x) // 가짜를 진짜로 인식한 정확도 D(G(z))를 통해 학습진행확인\n",
    "    print('EPOCH : {}/{}  //  d_loss  :  {}  // g_loss :  {}  // D(x) : {}  // D(G(z)) :  {}'.format(\n",
    "    epoch, EPOCHS, d_loss.item(), g_loss.item(), real_score.mean().item(), fake_score.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과물 시각화\n",
    "#만들고 싶은 아이템 생성하고 시각화 하기 \n",
    "# 0 = 티셔츠 / 1 = 바지 / 2 = 스웨터 / 3 = 드레스 / 4 = 코트 / 5 = 샌들 / 6 = 셔츠 / 7 = 신발 / 8 = 가방 / 9 = 부츠\n",
    "\n",
    "item_number = 4\n",
    "z = torch.randn(1, 100).to(DEVICE) #배치크기 1\n",
    "\n",
    "#torch.full은 새로운 텐서를 만드는 텐서 - 텐서 크기, 텐서 원소들을 초기화 할 값을 받아 아이템번호를 포함한 g_label이라는 1차원 텐서 생성\n",
    "g_label = torch.full((1, ), item_number, dtype = torch.long).to(DEVICE)\n",
    "\n",
    "#생성자에 무작위 텐서와 g_label을 입력하여 이미지생성\n",
    "sample_images = G(z, g_label)\n",
    "\n",
    "#시각화를 위한 넘파이 행렬로 변환 \n",
    "sample_images_img = np.reshape(sample_images.data.cpu().numpy()[0],(28,28))\n",
    "\n",
    "plt.imshow(sample_images_img, cmap = 'gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
